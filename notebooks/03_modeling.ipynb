{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff098558-dd18-43bb-b3dd-eacd58910da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# modules\n",
    "from src.config import OUTPUT_DIR, PROCESSED_DIR\n",
    "\n",
    "# vis config \n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "FIGSIZE = (10, 6)\n",
    "FIGSIZE_SMALL = (8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b79afbbd-f17f-46ef-acba-4630510d4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING PIPELINE A DATA\n",
      "================================================================================\n",
      "\n",
      "Shapes:\n",
      "  X_train_A: (20000, 8)\n",
      "  X_test_A:  (5000, 8)\n",
      "  y_train:   (20000,)\n",
      "  y_test:    (5000,)\n",
      "\n",
      "Features (8):\n",
      "  ['Age', 'Income', 'CreditScore', 'LoanAmount', 'EmploymentYears', 'NumDependents', 'DebtToIncome', 'EducationLevel']\n",
      "\n",
      "Data Quality:\n",
      "  X_train_A missing: 0\n",
      "  X_test_A missing:  0\n",
      "\n",
      "Class Distribution (Training):\n",
      "  Class 0: 13,137 (65.69%)\n",
      "  Class 1: 6,863 (34.31%)\n",
      "\n",
      "Pipeline A data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING PIPELINE A DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# load processed data\n",
    "X_train_A = np.load(PROCESSED_DIR / 'X_train_A.npy')\n",
    "X_test_A = np.load(PROCESSED_DIR / 'X_test_A.npy')\n",
    "y_train = np.load(PROCESSED_DIR / 'y_train.npy')\n",
    "y_test = np.load(PROCESSED_DIR / 'y_test.npy')\n",
    "\n",
    "# load feature names\n",
    "with open(PROCESSED_DIR / 'feature_names_A.txt', 'r') as f:\n",
    "    feature_names_A = f.read().split(r'\\n')\n",
    "\n",
    "# validation\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_train_A: {X_train_A.shape}\")\n",
    "print(f\"  X_test_A:  {X_test_A.shape}\")\n",
    "print(f\"  y_train:   {y_train.shape}\")\n",
    "print(f\"  y_test:    {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nFeatures ({len(feature_names_A)}):\")\n",
    "print(f\"  {feature_names_A}\")\n",
    "\n",
    "# check for missing values\n",
    "print(f\"\\nData Quality:\")\n",
    "print(f\"  X_train_A missing: {np.isnan(X_train_A).sum()}\")\n",
    "print(f\"  X_test_A missing:  {np.isnan(X_test_A).sum()}\")\n",
    "\n",
    "# class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\nClass Distribution (Training):\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Class {label}: {count:,} ({count/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nPipeline A data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbc2d63-aabe-4f73-94ce-cdc4064ebefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING PIPELINE B DATA\n",
      "================================================================================\n",
      "\n",
      "Shapes:\n",
      "  X_train_B: (20000, 14)\n",
      "  X_test_B:  (5000, 14)\n",
      "\n",
      "Features (14):\n",
      "   1. Age\n",
      "   2. Income\n",
      "   3. CreditScore\n",
      "   4. LoanAmount\n",
      "   5. EmploymentYears\n",
      "   6. NumDependents\n",
      "   7. DebtToIncome\n",
      "   8. EducationLevel\n",
      "   9. FavoriteColor_Green\n",
      "  10. FavoriteColor_Red\n",
      "  11. FavoriteColor_Yellow\n",
      "  12. Hobby_Reading\n",
      "  13. Hobby_Sports\n",
      "  14. Hobby_Traveling\n",
      "\n",
      "Data Quality:\n",
      "  X_train_B missing: 0\n",
      "  X_test_B missing:  0\n",
      "\n",
      "Pipeline B data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING PIPELINE B DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# load processed data\n",
    "X_train_B = np.load(PROCESSED_DIR / 'X_train_B.npy')\n",
    "X_test_B = np.load(PROCESSED_DIR / 'X_test_B.npy')\n",
    "\n",
    "# load feature names\n",
    "with open(PROCESSED_DIR / 'feature_names_B.txt', 'r') as f:\n",
    "    feature_names_B = f.read().split(r'\\n')\n",
    "\n",
    "# validation\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_train_B: {X_train_B.shape}\")\n",
    "print(f\"  X_test_B:  {X_test_B.shape}\")\n",
    "\n",
    "print(f\"\\nFeatures ({len(feature_names_B)}):\")\n",
    "for i, feat in enumerate(feature_names_B):\n",
    "    print(f\"  {i+1:2d}. {feat}\")\n",
    "\n",
    "# check for missing values\n",
    "print(f\"\\nData Quality:\")\n",
    "print(f\"  X_train_B missing: {np.isnan(X_train_B).sum()}\")\n",
    "print(f\"  X_test_B missing:  {np.isnan(X_test_B).sum()}\")\n",
    "\n",
    "print(\"\\nPipeline B data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad8d5cab-dd60-4aa7-a6c4-7c161b14d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-VALIDATION SETUP\n",
      "================================================================================\n",
      "\n",
      "Cross-Validation Configuration:\n",
      "  Strategy: Stratified K-Fold\n",
      "  Splits: 5\n",
      "  Shuffle: True\n",
      "  Random State: 42\n",
      "\n",
      "Verifying stratification:\n",
      "  Fold 1: 34.30% default rate\n",
      "  Fold 2: 34.30% default rate\n",
      "  Fold 3: 34.33% default rate\n",
      "  Fold 4: 34.33% default rate\n",
      "  Fold 5: 34.33% default rate\n",
      "\n",
      "Stratification Quality:\n",
      "  Mean default rate: 34.31%\n",
      "  Std default rate:  0.012%\n",
      "  Target (from train): 34.31%\n",
      "\n",
      "Cross-validation setup complete\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CROSS-VALIDATION SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# create stratified k-fold\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# verify stratification\n",
    "print(f\"\\nCross-Validation Configuration:\")\n",
    "print(f\"  Strategy: Stratified K-Fold\")\n",
    "print(f\"  Splits: {N_SPLITS}\")\n",
    "print(f\"  Shuffle: True\")\n",
    "print(f\"  Random State: {RANDOM_STATE}\")\n",
    "\n",
    "# check fold class distribution\n",
    "print(f\"\\nVerifying stratification:\")\n",
    "fold_distributions = []\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train_A, y_train)):\n",
    "    y_fold = y_train[val_idx]\n",
    "    default_rate = (y_fold == 1).sum() / len(y_fold)\n",
    "    fold_distributions.append(default_rate)\n",
    "    print(f\"  Fold {fold_idx + 1}: {default_rate*100:.2f}% default rate\")\n",
    "\n",
    "print(f\"\\nStratification Quality:\")\n",
    "print(f\"  Mean default rate: {np.mean(fold_distributions)*100:.2f}%\")\n",
    "print(f\"  Std default rate:  {np.std(fold_distributions)*100:.3f}%\")\n",
    "print(f\"  Target (from train): {(y_train==1).sum()/len(y_train)*100:.2f}%\")\n",
    "\n",
    "print(\"\\nCross-validation setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "683ef94e-7e4f-472d-90fa-41c4e0f4230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATION METRICS SETUP\n",
      "================================================================================\n",
      "\n",
      "Metrics for evaluation:\n",
      "  Primary:   ROC-AUC (threshold-independent, handles imbalance)\n",
      "  Secondary: F1, Precision, Recall (threshold-dependent)\n",
      "  Additional: Accuracy, Brier Score (calibration)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EVALUATION METRICS SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# define scoring metrics for cross-validation\n",
    "SCORING_METRICS = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'f1': 'f1',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "print(\"\\nMetrics for evaluation:\")\n",
    "print(\"  Primary:   ROC-AUC (threshold-independent, handles imbalance)\")\n",
    "print(\"  Secondary: F1, Precision, Recall (threshold-dependent)\")\n",
    "print(\"  Additional: Accuracy, Brier Score (calibration)\")\n",
    "\n",
    "# helper function for consistent evaluation\n",
    "def evaluate_model(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv,\n",
    "    model_name: str,\n",
    "    pipeline_name: str\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with CV and test set metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with CV scores, test scores, and predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # CV\n",
    "    cv_results = cross_validate(\n",
    "        model, X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=SCORING_METRICS,\n",
    "        return_train_score=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # test set predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # test set metrics\n",
    "    test_metrics = {\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'brier': brier_score_loss(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'pipeline': pipeline_name,\n",
    "        'cv_scores': cv_results,\n",
    "        'test_metrics': test_metrics,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1e13c-2c7d-417c-88e4-78f480837f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
